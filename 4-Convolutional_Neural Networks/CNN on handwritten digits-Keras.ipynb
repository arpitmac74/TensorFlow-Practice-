{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Pics/MLSb-T.png\" width=\"160\">\n",
    "<br><br>\n",
    "<center><u><H1>CNN on Handwritten Digits with Keras</H1></u></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "sess = tf.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(\n",
    "    sess\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "D:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_, y_train_), (X_test_, y_test_) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the training data to represent one-channel image input(grayscale)\n",
    "img_rows, img_cols = X_train_[0].shape[0], X_train_[0].shape[1]\n",
    "X_train = X_train_.reshape(X_train_.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test_.reshape(X_test_.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the input data:\n",
    "X_train_std = X_train.astype('float32')/255.\n",
    "X_test_std = X_test.astype('float32')/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encode the labels:\n",
    "n_classes = len(set(y_train_))\n",
    "y_train = to_categorical(y_train_, n_classes)\n",
    "y_test = to_categorical(y_test_, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv2D in module keras.layers.convolutional:\n",
      "\n",
      "class Conv2D(_Conv)\n",
      " |  2D convolution layer (e.g. spatial convolution over images).\n",
      " |  \n",
      " |  This layer creates a convolution kernel that is convolved\n",
      " |  with the layer input to produce a tensor of\n",
      " |  outputs. If `use_bias` is True,\n",
      " |  a bias vector is created and added to the outputs. Finally, if\n",
      " |  `activation` is not `None`, it is applied to the outputs as well.\n",
      " |  \n",
      " |  When using this layer as the first layer in a model,\n",
      " |  provide the keyword argument `input_shape`\n",
      " |  (tuple of integers, does not include the batch axis),\n",
      " |  e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
      " |  in `data_format=\"channels_last\"`.\n",
      " |  \n",
      " |  # Arguments\n",
      " |      filters: Integer, the dimensionality of the output space\n",
      " |          (i.e. the number of output filters in the convolution).\n",
      " |      kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
      " |          height and width of the 2D convolution window.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |      strides: An integer or tuple/list of 2 integers,\n",
      " |          specifying the strides of the convolution\n",
      " |          along the height and width.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |          Specifying any stride value != 1 is incompatible with specifying\n",
      " |          any `dilation_rate` value != 1.\n",
      " |      padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
      " |          Note that `\"same\"` is slightly inconsistent across backends with\n",
      " |          `strides` != 1, as described\n",
      " |          [here](https://github.com/keras-team/keras/pull/9473#issuecomment-372166860)\n",
      " |      data_format: A string,\n",
      " |          one of `\"channels_last\"` or `\"channels_first\"`.\n",
      " |          The ordering of the dimensions in the inputs.\n",
      " |          `\"channels_last\"` corresponds to inputs with shape\n",
      " |          `(batch, height, width, channels)` while `\"channels_first\"`\n",
      " |          corresponds to inputs with shape\n",
      " |          `(batch, channels, height, width)`.\n",
      " |          It defaults to the `image_data_format` value found in your\n",
      " |          Keras config file at `~/.keras/keras.json`.\n",
      " |          If you never set it, then it will be \"channels_last\".\n",
      " |      dilation_rate: an integer or tuple/list of 2 integers, specifying\n",
      " |          the dilation rate to use for dilated convolution.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |          Currently, specifying any `dilation_rate` value != 1 is\n",
      " |          incompatible with specifying any stride value != 1.\n",
      " |      activation: Activation function to use\n",
      " |          (see [activations](../activations.md)).\n",
      " |          If you don't specify anything, no activation is applied\n",
      " |          (ie. \"linear\" activation: `a(x) = x`).\n",
      " |      use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |      kernel_initializer: Initializer for the `kernel` weights matrix\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      bias_initializer: Initializer for the bias vector\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      kernel_regularizer: Regularizer function applied to\n",
      " |          the `kernel` weights matrix\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      bias_regularizer: Regularizer function applied to the bias vector\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      activity_regularizer: Regularizer function applied to\n",
      " |          the output of the layer (its \"activation\").\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      kernel_constraint: Constraint function applied to the kernel matrix\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |      bias_constraint: Constraint function applied to the bias vector\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |  \n",
      " |  # Input shape\n",
      " |      4D tensor with shape:\n",
      " |      `(batch, channels, rows, cols)`\n",
      " |      if `data_format` is `\"channels_first\"`\n",
      " |      or 4D tensor with shape:\n",
      " |      `(batch, rows, cols, channels)`\n",
      " |      if `data_format` is `\"channels_last\"`.\n",
      " |  \n",
      " |  # Output shape\n",
      " |      4D tensor with shape:\n",
      " |      `(batch, filters, new_rows, new_cols)`\n",
      " |      if `data_format` is `\"channels_first\"`\n",
      " |      or 4D tensor with shape:\n",
      " |      `(batch, new_rows, new_cols, filters)`\n",
      " |      if `data_format` is `\"channels_last\"`.\n",
      " |      `rows` and `cols` values might have changed due to padding.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Conv2D\n",
      " |      _Conv\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _Conv:\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An output shape tuple.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Adds losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_metric(self, value, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          value: Metric tensor.\n",
      " |          name: String metric name.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Adds updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Counts the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |  \n",
      " |  metrics\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Conv2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "batch_size = 128\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.4672 - accuracy: 0.9193\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.1073 - accuracy: 0.9696\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 11s 192us/step - loss: 0.0833 - accuracy: 0.9757\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0660 - accuracy: 0.9808\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0556 - accuracy: 0.9832\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0552 - accuracy: 0.9833\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0493 - accuracy: 0.9851\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0455 - accuracy: 0.9856\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0394 - accuracy: 0.9881\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.0400 - accuracy: 0.9876\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.0392 - accuracy: 0.9880\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.0373 - accuracy: 0.9887\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.0324 - accuracy: 0.9897\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.0328 - accuracy: 0.9900\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.0350 - accuracy: 0.9893\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.0304 - accuracy: 0.9908\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.0297 - accuracy: 0.9907\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.0254 - accuracy: 0.9919\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.0276 - accuracy: 0.9914\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.0287 - accuracy: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x296550c2668>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 126us/step\n",
      "Test loss: 0.03473031025558213\n",
      "Test accuracy: 0.9927999973297119\n"
     ]
    }
   ],
   "source": [
    "#Show the results on the test set:\n",
    "#verbose: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "n = 10\n",
    "plt.figure(figsize=(15,15))\n",
    "for i in range(n):\n",
    "    plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(X_test[i, :, :, 0], cmap='gray')\n",
    "    plt.title(\"Label: {}\\nPredicted: {}\".format(np.argmax(y_test[i]), np.argmax(preds[i])))\n",
    "    plt.axis('off')\n",
    "plt.show()          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting misclassified images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "misc = 0\n",
    "for i in range(len(y_test)):\n",
    "    if(misc==10):\n",
    "        break\n",
    "    label = np.argmax(y_test[i])\n",
    "    pred = np.argmax(preds[i])\n",
    "    if label != pred:\n",
    "        plt.subplot(1, n, misc + 1)\n",
    "        plt.imshow(X_test[i, :, :, 0], cmap='gray')\n",
    "        plt.title(\"Label: {}\\nPredicted: {}\".format(label, pred))\n",
    "        plt.axis('off')\n",
    "        misc+=1\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reference:\n",
    "\n",
    "https://keras.io/datasets/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpu",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
